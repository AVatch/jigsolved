{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bounding_box(points):\n",
    "    \"\"\"Takes a list of (x, y) and returns upper left and lower right points\"\"\"\n",
    "    x_min = min([x for x, _ in points])\n",
    "    x_max = max([x for x, _ in points])\n",
    "    y_min = min([y for _, y in points])\n",
    "    y_max = max([y for _, y in points])\n",
    "    return (x_min, y_min), (x_max, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_edges(img):\n",
    "    \"\"\"Takes an image and gives an array same dimension as image that has 1 if\n",
    "    edge, 0 if not for each pixel.\"\"\"\n",
    "    lowThreshold = 30\n",
    "    ratio = 3\n",
    "    kernel_size = 3\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(gray,(3,3),6)\n",
    "    img = cv2.Canny(img,lowThreshold,lowThreshold*ratio,apertureSize = kernel_size)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_blob(img):\n",
    "    hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    img = cv2.GaussianBlur(hsv,(5,5),6)\n",
    "    return cv2.inRange(img, (0,100,34), (255,255,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_nonzero(img):\n",
    "    \"\"\"Return a list of (x,y) for each point in the image that is not zero\"\"\"\n",
    "    edge_points = []\n",
    "    for i, row in enumerate(img):\n",
    "        for j, col in enumerate(row):\n",
    "            if col != 0:\n",
    "                edge_points.append((j, i))\n",
    "    return edge_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trimmed_box(img):\n",
    "    \"\"\"Approximate the square bit off the puzzle piece in img\"\"\"\n",
    "    edges = cv2.bitwise_or(get_blob(img), get_edges(img))\n",
    "    edge_points = get_all_nonzero(edges)\n",
    "    (x_min, y_min), (x_max, y_max) = bounding_box(edge_points)\n",
    "\n",
    "    def should_trim(img, (x_min, y_min), (x_max, y_max)):\n",
    "        threshold = 1.0 / 25\n",
    "        img = img[y_min:y_max,x_min:x_max]\n",
    "        if np.size(img):\n",
    "            return float(np.count_nonzero(img))/np.size(img) < threshold\n",
    "        return False\n",
    "\n",
    "    trim_step = 25\n",
    "\n",
    "    new_x_min = x_min\n",
    "    while should_trim(edges, (new_x_min, y_min), (new_x_min + trim_step, y_max)):\n",
    "        new_x_min += trim_step\n",
    "\n",
    "    new_x_max = x_max\n",
    "    while should_trim(edges, (new_x_max - trim_step, y_min), (new_x_max, y_max)):\n",
    "        new_x_max -= trim_step\n",
    "\n",
    "    new_y_min = y_min\n",
    "    while should_trim(edges, (x_min, new_y_min), (x_max, new_y_min+trim_step)):\n",
    "        new_y_min += trim_step\n",
    "\n",
    "    new_y_max = y_max\n",
    "    while should_trim(edges, (x_min, new_y_max - trim_step), (x_max, new_y_max)):\n",
    "        new_y_max -= trim_step\n",
    "\n",
    "    return new_x_min, new_x_max, new_y_min, new_y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     sift = cv2.SIFT()\n",
    "    sift = cv2.xfeatures2d.SURF_create()\n",
    "    return sift.detectAndCompute(gray_img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_image_box(outer_img, inner_img):\n",
    "    (outer_points, outer_descs) = find_features(outer_img)\n",
    "    (inner_points, inner_descs) = find_features(inner_img)\n",
    "    \n",
    "    matcher = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_KDTREE, trees = 4), {})\n",
    "#     bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "#     matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    \n",
    "    matches = matcher.knnMatch(inner_descs.astype(np.float32), outer_descs.astype(np.float32), 2)\n",
    "    matches = [m[0] for m in matches if len(m) == 2 and m[0].distance < m[1].distance * 0.75]\n",
    "    p0 = [inner_points[m.queryIdx].pt for m in matches]\n",
    "    p1 = [outer_points[m.trainIdx].pt for m in matches]\n",
    "    p0, p1 = np.float32((p0, p1))\n",
    "    H, status = cv2.findHomography(p0, p1, cv2.RANSAC, 3.0)\n",
    "    height, width = inner_img.shape[:2]\n",
    "    box = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
    "    return cv2.perspectiveTransform(box.reshape(1, -1, 2), H).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_puzzle(piece_img, board_img):\n",
    "    piece_img = cv2.imread(piece_img)\n",
    "    board_img = cv2.imread(board_img)\n",
    "    x_min, x_max, y_min, y_max = get_trimmed_box(piece_img)\n",
    "    piece = piece_img[y_min:y_max,x_min:x_max]\n",
    "    cv2.imwrite('./CroppedPiece.jpg', piece)\n",
    "\n",
    "    return find_image_box(board_img, piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/tmp/opencv320160216-21458-12empfe/opencv-3.1.0/modules/python/src2/cv2.cpp:163: error: (-215) The data should normally be NULL! in function allocate\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1bd4ba0c3ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0msolve_puzzle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./template_white_bg.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./puzzle_master_image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-a056320ae65c>\u001b[0m in \u001b[0;36msolve_puzzle\u001b[0;34m(piece_img, board_img)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./CroppedPiece.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind_image_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-8ad12ad862ec>\u001b[0m in \u001b[0;36mfind_image_box\u001b[0;34m(outer_img, inner_img)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_descs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouter_descs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minner_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueryIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /tmp/opencv320160216-21458-12empfe/opencv-3.1.0/modules/python/src2/cv2.cpp:163: error: (-215) The data should normally be NULL! in function allocate\n"
     ]
    }
   ],
   "source": [
    "print solve_puzzle('./template_white_bg.jpg', './puzzle_master_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
